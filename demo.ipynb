{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T11:28:55.179905Z",
     "start_time": "2025-04-21T11:28:55.176520Z"
    }
   },
   "source": [
    "# Prepare the Environment\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:05:49.808675Z",
     "start_time": "2025-04-21T11:05:48.664270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup Hyperparameters\n",
    "# Hyperparameters\n",
    "batch_size = 4  # How many batches per training step\n",
    "context_length = 16  # Length of the token chunk each batch\n",
    "d_model = 64  # The vector size of the token embeddings\n",
    "num_layers = 8  # Number of transformer blocks\n",
    "num_heads = 4  # Number of heads in Multi-head attention # 我们的代码中通过 d_model / num_heads = 来获取 head_size\n",
    "learning_rate = 1e-3  # 0.001\n",
    "dropout = 0.1 # Dropout rate\n",
    "max_iters = 5000  # Total of training iterations\n",
    "eval_interval = 50  # How often to evaluate the model\n",
    "eval_iters = 20  # How many iterations to average the loss over when evaluating the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Instead of using the cpu, we'll use the GPU if it's available.\n",
    "\n",
    "TORCH_SEED = 1337\n",
    "torch.manual_seed(TORCH_SEED)"
   ],
   "id": "afd4e02703444b73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x272791ddd30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:05:54.669076Z",
     "start_time": "2025-04-21T11:05:54.661650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the Dataset\n",
    "# download a sample txt file from https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt\n",
    "if not os.path.exists('sales_textbook.txt'):\n",
    "    url = 'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'\n",
    "    with open('sales_textbook.txt', 'w') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "\n",
    "with open('sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ],
   "id": "6d0bfd1654e21f29",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:09:23.441940Z",
     "start_time": "2025-04-21T11:09:22.608725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Tokenization\n",
    "# Using TikToken to tokenize the source text\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenized_text = torch.tensor(encoding.encode(text)) # size of tokenized source text is 77,919\n",
    "vocab_size = len(set(tokenized_text)) # size of vocabulary is 3,771\n",
    "max_token_value = max(tokenized_text)\n",
    "\n",
    "print(f\"Tokenized text size: {len(tokenized_text)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"The maximum value in the tokenized text is: {max_token_value}\")"
   ],
   "id": "e9eef85cc0b4b539",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text size: 77919\n",
      "Vocabulary size: 77919\n",
      "The maximum value in the tokenized text is: 100069\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:09:25.836171Z",
     "start_time": "2025-04-21T11:09:25.829257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Word Embedding\n",
    "# Split train and validation\n",
    "split_idx = int(len(tokenized_text) * 0.8)\n",
    "train_data = tokenized_text[:split_idx]\n",
    "val_data = tokenized_text[split_idx:]\n",
    "\n",
    "# Prepare data for training batch\n",
    "# Prepare data for training batch\n",
    "data = train_data\n",
    "idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n",
    "x_batch = torch.stack([data[idx:idx + context_length] for idx in idxs])\n",
    "y_batch = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs])\n",
    "print(x_batch.shape, x_batch.shape)"
   ],
   "id": "ce93ae375dae2a63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16]) torch.Size([4, 16])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:19:36.252443Z",
     "start_time": "2025-04-21T11:19:36.210237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Positional Encoding\n",
    "# Define Token Embedding look-up table\n",
    "token_embedding_lookup_table = nn.Embedding(max_token_value, d_model)\n",
    "\n",
    "# Get X and Y embedding\n",
    "x = token_embedding_lookup_table(x_batch.data)\n",
    "y = token_embedding_lookup_table(y_batch.data)\n",
    "\n",
    "# Define Position Encoding look-up table\n",
    "position_encoding_lookup_table = torch.zeros(context_length, d_model) # initial with zeros with shape (context_length, d_model)\n",
    "position = torch.arange(0, context_length, dtype=torch.float).unsqueeze(1)\n",
    "# apply the sine & cosine\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "position_encoding_lookup_table[:, 0::2] = torch.sin(position * div_term)\n",
    "position_encoding_lookup_table[:, 1::2] = torch.cos(position * div_term)\n",
    "position_encoding_lookup_table = position_encoding_lookup_table.unsqueeze(0).expand(batch_size, -1, -1) #add batch to the first dimension\n",
    "\n",
    "print(\"Position Encoding Look-up Table: \", position_encoding_lookup_table.shape)\n",
    "\n",
    "# Add positional encoding into the input embedding vector\n",
    "input_embedding_x = x + position_encoding_lookup_table # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "input_embedding_y = y + position_encoding_lookup_table\n",
    "\n",
    "X = input_embedding_x\n",
    "\n",
    "# x_plot = input_embedding_x[0].detach().cpu().numpy()\n",
    "# print(\"Final Input Embedding of x: \\n\")\n",
    "# pd.DataFrame(x_plot)"
   ],
   "id": "e697fc0207eef752",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Encoding Look-up Table:  torch.Size([4, 16, 64])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:13:13.664793Z",
     "start_time": "2025-04-21T11:13:13.656719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare Q,K,V\n",
    "# Prepare Query, Key, Value for Multi-head Attention\n",
    "\n",
    "query = key = value = X # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "\n",
    "# Define Query, Key, Value weight matrices\n",
    "Wq = nn.Linear(d_model, d_model)\n",
    "Wk = nn.Linear(d_model, d_model)\n",
    "Wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "Q = Wq(query) #[4, 16, 64]\n",
    "Q = Q.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "K = Wk(key) #[4, 16, 64]\n",
    "K = K.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "V = Wv(value) #[4, 16, 64]\n",
    "V = V.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]"
   ],
   "id": "489ee3ba588afc96",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:13:50.308773Z",
     "start_time": "2025-04-21T11:13:50.304294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transpose q,k,v from [batch_size, context_length, num_heads, head_size] to [batch_size, num_heads, context_length, head_size]\n",
    "# The reason is that treat each batch with \"num_heads\" as its first dimension.\n",
    "Q = Q.transpose(1, 2) # [4, 4, 16, 16]\n",
    "K = K.transpose(1, 2) # [4, 4, 16, 16]\n",
    "V = V.transpose(1, 2) # [4, 4, 16, 16]"
   ],
   "id": "fd55e5c0bc3ffcd0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:14:10.556716Z",
     "start_time": "2025-04-21T11:14:10.552038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate QK^T Attention\n",
    "# Calculate the attention score betwee Q and K^T\n",
    "attention_score = torch.matmul(Q, K.transpose(-2, -1))"
   ],
   "id": "793f306038f6ba1a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:19:11.225852Z",
     "start_time": "2025-04-21T11:19:11.222442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Then Scale the attention score by the square root of the head size\n",
    "attention_score = attention_score / torch.sqrt(torch.tensor(d_model // num_heads, dtype=torch.float))\n",
    "# pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ],
   "id": "ea345f3723d09397",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:19:15.539208Z",
     "start_time": "2025-04-21T11:19:15.534210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Mask to attention scores\n",
    "attention_score = attention_score.masked_fill(torch.triu(torch.ones(attention_score.shape[-2:]), diagonal=1).bool(), float('-inf')) #[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]\n",
    "# pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ],
   "id": "ea0c938c76f9baa",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:16:48.474145Z",
     "start_time": "2025-04-21T11:16:48.469988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Softmax the attention score\n",
    "attention_score = torch.softmax(attention_score, dim=-1)  #[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]"
   ],
   "id": "df5e3c4ec009ebd1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:17:19.977672Z",
     "start_time": "2025-04-21T11:17:19.971280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the V attention output\n",
    "A = torch.matmul(attention_score, V) # [4, 4, 16, 16] [batch_size, num_heads, context_length, head_size]\n",
    "A.shape"
   ],
   "id": "edcfae3c6b0e6f1d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 16, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:17:31.012258Z",
     "start_time": "2025-04-21T11:17:31.007597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = A.transpose(1, 2) # [4, 16, 4, 16] [batch_size, context_length, num_heads, head_size]\n",
    "A = A.reshape(batch_size, -1, d_model) # [4, 16, 64] [batch_size, context_length, d_model]"
   ],
   "id": "ec7b2b189f9fbf75",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:17:38.758200Z",
     "start_time": "2025-04-21T11:17:38.752709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the output weight matrix\n",
    "Wo = nn.Linear(d_model, d_model)\n",
    "output = Wo(A) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "\n",
    "print(output.shape)"
   ],
   "id": "9213cda7490aa34e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 64])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:17:59.929872Z",
     "start_time": "2025-04-21T11:17:59.923500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add residual connection\n",
    "output = output + X\n",
    "\n",
    "# Add Layer Normalization\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "output = layer_norm(output)"
   ],
   "id": "201c5204628f6e12",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:14.132233Z",
     "start_time": "2025-04-21T11:18:14.121650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define Feed Forward Network\n",
    "output = nn.Linear(d_model, d_model * 4)(output)\n",
    "output = nn.ReLU()(output)\n",
    "output = nn.Linear(d_model * 4, d_model)(output)\n",
    "output = torch.dropout(output, p=dropout, train=True)"
   ],
   "id": "d08c8d3ac26f36b8",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:24.582473Z",
     "start_time": "2025-04-21T11:18:24.577547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add residual connection\n",
    "output = output + X\n",
    "# Add Layer Normalization\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "output = layer_norm(output)"
   ],
   "id": "6221e386e808abfe",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:30:08.559539Z",
     "start_time": "2025-04-21T11:30:08.510944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# apply final linear layer to get the logits\n",
    "logits = nn.Linear(d_model, max_token_value+1)(output)\n",
    "logits.shape"
   ],
   "id": "b1886d1788753901",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 100070])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:30:33.419795Z",
     "start_time": "2025-04-21T11:30:33.394361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "possibilities = F.softmax(logits, dim=-1)\n",
    "predicted_index = torch.argmax(possibilities[0, 0]).item()\n",
    "print(predicted_index)\n",
    "encoding.decode([predicted_index])"
   ],
   "id": "ce47464dd8f405f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tog'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
